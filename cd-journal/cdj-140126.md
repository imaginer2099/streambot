#14 Jan 2026 

##15:41
I just reconfigured my approach to how I want to do this project, as well as its entire scope. There is this thing with ChatGPT called tool calling. I am doing research on it and how it works. It is a means to procrastinate, I know. However, I do not mind that. I am basically trying to figure out how I can best work with an LLM. Do I need to type giant prompts and multiple schemas? Well, apparently the answer is "no". All I have to do is give the LLM the user prompt and then a list of all the available tools that are at the disposal of the program. For example, it can pick between writing a quotation, an invoice, or finding the perfect price for a product, all depending on what it reasons to be the user's intent. It is fuzzily matching the user intent with the appropriate tool (my own Python function) for the job. This removes the need for something that does data validation because we can use Pydantic for error handling the moment there is something missing. Then, the model itself will basically say, "I have no idea what you are talking about."

This means that no matter what, I will have good flow so long as I have good design. So, now I get to focus purely on building a system. I get to focus on code. This is a lot more exciting and manageable. I really did not want to have to plan out schemas and giant prompts. Now I can focus on system architecture.

Where would FastAPI fit into all of this if I want to create a Streamlit agent? Well, not much. I mean Streamlit is the website. So, you would not need to build an API for it. Plus, I am specifically designing this for me and my mother, as well as anyone that we train to work for the family business. So really, for the time being, FastAPI does not fit anywhere. All the pieces will fit together regardless.
What I need to do is simply plan for the system. You would have modules for the database setup, the other APIs (maybe we need something advanced for scraping, or just its own entire module for the tools), and then the main project file where everything is orchestrated. That is it:

1) db.py
2) price_finder.py
3) app.py (Streamlit front end)

That is all that is needed. The price_finder.py and app.py modules would be thicker than a snicker but I think that is okay. I mean, the simplicity would be easier to follow, and we can always abstract certain functions to methods in seperate classes and modules later. Better to assume simplicity than to submit to complexity.

##16:25
I need to do research on how I can web crawl for the best pricing information for a quotation. How it would work would be:

- The user mentions that they want a price for a specifc item and they mention the quantities of materials, along with an intended pricing strategy.
- The LLM determines that price_finder.py module needs to be accessed
- The program calculates the manufacturing cost of the product in question
- It then takes the information about the product and searches online for similar products
- It finds the most popular, most affordable, and most expensive products (all categorised as ordered).
- It compares the manufacturing cost and to the final cost, defining its comparisons as markup percentages.
- It then programmatically suggests the most competitive option based on the intended pricing strategy.
